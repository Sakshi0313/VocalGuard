# ğŸ¤ VocalGuard - AI-Powered Voice Deepfake Detection


VocalGuard is an advanced AI-powered web application that detects voice deepfakes and synthetic audio with high accuracy. Using state-of-the-art machine learning models, it helps protect against voice cloning attacks and ensures audio authenticity.

## âœ¨ Features

- ğŸ¯ **Deepfake Detection**: Accurately identifies cloned voices using advanced AI
- ğŸ“Š **Confidence Scores**: Provides percentage breakdown of real vs. synthetic predictions
- ğŸ“ **Easy Upload**: Supports voice recording or file upload in multiple formats (WAV, MP3, FLAC, OGG, M4A, WebM)
- ğŸ“ˆ **Visual Insights**: Displays mel spectrograms for audio forensic analysis
- ğŸ“± **Responsive Design**: Works seamlessly on desktop and mobile devices
- ğŸ”„ **Real-time Processing**: Fast analysis with immediate results
- ğŸ“‹ **Analytics Dashboard**: Track analysis history and statistics
- ğŸ¨ **Modern UI**: Beautiful interface with particle animations and smooth transitions

## ğŸ—ï¸ Architecture

VocalGuard consists of three main components:

1. **Frontend** (React + Vite): Modern web interface with real-time audio recording and file upload
2. **Backend Proxy** (Node.js + Express): Handles file uploads and proxies requests to ML API
3. **ML API** (Python + Flask): TensorFlow Lite model for deepfake detection with feature extraction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontendâ”‚â”€â”€â”€â–¶â”‚  Node.js Proxy  â”‚â”€â”€â”€â–¶â”‚   Python ML API â”‚
â”‚   (Port 5173)   â”‚    â”‚   (Port 3000)   â”‚    â”‚   (Port 5000)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Frontend
- **React 19** - Modern UI library
- **Vite** - Fast build tool and dev server
- **Tailwind CSS** - Utility-first CSS framework
- **Framer Motion** - Smooth animations
- **Recharts** - Data visualization
- **React Hot Toast** - Notifications

### Backend
- **Node.js** - JavaScript runtime
- **Express** - Web framework
- **Multer** - File upload handling
- **Axios** - HTTP client
- **CORS** - Cross-origin resource sharing

### ML API
- **Python 3.8+** - Programming language
- **Flask** - Lightweight web framework
- **TensorFlow Lite** - Optimized ML inference
- **Librosa** - Audio analysis library
- **NumPy** - Numerical computing
- **Matplotlib** - Plotting and visualization

## ğŸ“‹ Prerequisites

Before running VocalGuard, ensure you have:

- **Node.js** (v16 or higher)
- **Python** (v3.8 or higher)
- **FFmpeg** (for audio format conversion)

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/Sakshi0313/VocalGuard.git
cd VocalGuard
```

### 2. Install Frontend Dependencies
```bash
npm install
```

### 3. Install Backend Dependencies
```bash
cd backend
npm install
cd ..
```

### 4. Set Up Python ML API
```bash
cd ml_api
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate

pip install -r requirements.txt
cd ..
```

### 5. Start All Services

**Terminal 1 - ML API:**
```bash
cd ml_api
python app.py
```

**Terminal 2 - Backend Proxy:**
```bash
cd backend
npm start
```

**Terminal 3 - Frontend:**
```bash
npm run dev
```

### 6. Access the Application
Open your browser and navigate to `http://localhost:5173`

## ğŸ“ Project Structure

```
VocalGuard/
â”œâ”€â”€ src/                          # React frontend source
â”‚   â”œâ”€â”€ components/               # React components
â”‚   â”‚   â”œâ”€â”€ AudioUpload.jsx      # File upload & recording
â”‚   â”‚   â”œâ”€â”€ ResultCard.jsx       # Analysis results display
â”‚   â”‚   â”œâ”€â”€ Analytics.jsx        # Statistics dashboard
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ App.jsx                  # Main application component
â”‚   â””â”€â”€ main.jsx                 # Application entry point
â”œâ”€â”€ backend/                     # Node.js proxy server
â”‚   â”œâ”€â”€ server.js               # Express server
â”‚   â”œâ”€â”€ package.json            # Backend dependencies
â”‚   â””â”€â”€ uploads/                # Temporary file storage
â”œâ”€â”€ ml_api/                     # Python ML API
â”‚   â”œâ”€â”€ app.py                  # Flask application
â”‚   â”œâ”€â”€ tflite_learn_815023_3.tflite  # TensorFlow Lite model
â”‚   â”œâ”€â”€ scaler.pkl              # Feature scaler
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ uploads/                # Audio files & spectrograms
â”œâ”€â”€ public/                     # Static assets
â”œâ”€â”€ dist/                       # Production build
â””â”€â”€ package.json               # Frontend dependencies
```

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file in the root directory:
```env
VITE_API_URL=http://localhost:3000
REACT_APP_ML_API_URL=http://localhost:5000
```

### Model Configuration
The ML model uses the following parameters:
- **Sample Rate**: 16kHz
- **Duration**: 3 seconds
- **Features**: 26 MFCC and spectral features
- **Model**: TensorFlow Lite optimized for inference

## ğŸ§ª How It Works

1. **Audio Input**: User uploads audio file or records voice
2. **Preprocessing**: Audio is converted to WAV, normalized, and padded/trimmed to 3 seconds
3. **Feature Extraction**: 26 features extracted including:
   - Chroma features
   - RMS energy
   - Spectral centroid, bandwidth, rolloff
   - Zero crossing rate
   - 20 MFCC coefficients
4. **Normalization**: Features are standardized using pre-computed mean and std
5. **Prediction**: TensorFlow Lite model classifies as REAL or FAKE
6. **Visualization**: Mel spectrogram generated for visual analysis

## ğŸ“Š Model Performance

The AI model achieves:
- **Accuracy**: ~90-99% on test datasets
- **Processing Time**: <2 seconds per audio file
- **Supported Formats**: WAV, MP3, FLAC, OGG, M4A, WebM
- **Model Size**: Optimized TensorFlow Lite model (~2MB)

## ğŸš€ Deployment

### GitHub Pages (Frontend Only)
```bash
npm run build
npm run deploy
```

### Full Stack Deployment
For production deployment, consider:
- **Frontend**: Vercel, Netlify, or GitHub Pages
- **Backend**: Heroku, Railway, or DigitalOcean
- **ML API**: Google Cloud Run, AWS Lambda, or dedicated server

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- TensorFlow team for the machine learning framework
- Librosa developers for audio processing capabilities
- React and Vite communities for excellent development tools
- Open source community for various libraries and tools used

---

â­ If you found this project helpful, please give it a star on GitHub!
